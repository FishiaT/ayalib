# ayalib
 a python wrapper for llama.cpp server

## why?
this is something that I wrote SPECIFICALLY for my own needs, and as such it only support the [llama.cpp server](https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md) and is very minimal.

the code itself is not great in any way (actually it's the other way around!), but it works and that's all that matters.

please do not use this for your own projects (unless you want to I guess.)